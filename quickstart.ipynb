
        {
            "cells": [
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [],
           "source": ["// Google Colab only: uncomment and run the following to install dotnet and the F# kernel\n",
"// !bash \u003c(curl -Ls https://raw.githubusercontent.com/gbaydin/scripts/main/colab_dotnet6.sh)\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": null, "outputs": [],
           "source": ["// Import Furnace package\n",
"#r \"nuget: Furnace-lite,1.0.9\"\n",
"#r \"nuget: SixLabors.ImageSharp,1.0.1\"\n",
"\n",
"// Set dotnet interactive formatter to plaintext\n",
"Formatter.SetPreferredMimeTypesFor(typeof\u003cobj\u003e, \"text/plain\")\n",
"Formatter.Register(fun (x:obj) (writer: TextWriter) -\u003e fprintfn writer \"%120A\" x )\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["[![Binder](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fsprojects/Furnace/blob/master/quickstart.ipynb)\u0026emsp;\n",
"[![Script](img/badge-script.svg)](quickstart.fsx)\u0026emsp;\n",
"[![Script](img/badge-notebook.svg)](quickstart.ipynb)\n",
"\n",
"# Quickstart\n",
"\n",
"Here we cover some key tasks involved in a typical machine learning pipeline and how these can be implemented with Furnace. Note that a significant part of Furnace\u0027s design has been influenced by [PyTorch](https://pytorch.org/) and you would feel mostly at home if you have familiarity with PyTorch.\n",
"\n",
"## Datasets and Data Loaders\n",
"\n",
"Furnace provides the [Dataset](https://fsprojects.github.io/Furnace/reference/furnace-data-dataset.html) type that represents a data source and the [DataLoader](https://fsprojects.github.io/Furnace/reference/furnace-data-dataloader.html) type that handles the loading of data from datasets and iterating over [minibatches](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Iterative_method) of data.\n",
"\n",
"See the [Furnace.Data](/Furnace/reference/furnace-data.html) namespace for the full API reference.\n",
"\n",
"### Datasets\n",
"\n",
"Furnace has ready-to-use types that cover main datasets typically used in machine learning, such as [MNIST](https://fsprojects.github.io/Furnace/reference/furnace-data-mnist.html), [CIFAR10](https://fsprojects.github.io/Furnace/reference/furnace-data-cifar10.html), [CIFAR100](https://fsprojects.github.io/Furnace/reference/furnace-data-cifar100.html), and also more generic dataset types such as [TensorDataset](https://fsprojects.github.io/Furnace/reference/furnace-data-tensordataset.html) or [ImageDataset](https://fsprojects.github.io/Furnace/reference/furnace-data-imagedataset.html).\n",
"\n",
"The following loads the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and shows one image entry and the corresponding label.\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 2, "outputs": [
          {
           "data": {
            "text/plain": ["No value returned by any evaluator"]
        },
           "execution_count": 2,
           "metadata": {},
           "output_type": "execute_result"
          }],
           "source": ["open Furnace\n",
"open Furnace.Data\n",
"\n",
"// First ten images in MNIST training set\n",
"let dataset = MNIST(\"../data\", train=true, transform=id, n=10)\n",
"\n",
"// Inspect a single image and label\n",
"let data, label = dataset[7]\n",
"\n",
"// Save image to file\n",
"data.saveImage(\"test.png\")\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 4, "outputs": [
          {
           "data": {
            "text/plain": ["Data: \"                            ",
"                            ",
"                            ",
"                            ",
"                            ",
"           ~-}@#####Z       ",
"         -j*W########J\u0027     ",
"         O############i     ",
"         [##Mxxxxo####i     ",
"          ::^    \u0027W##Z      ",
"                 |\u0026##f      ",
"                (o###\u0027      ",
"              (q%###d.      ",
"         \"uaaa####8}:       ",
"        _m########O         ",
"        _*####@####?        ",
"         \"v\u003c____f##?        ",
"                `##?        ",
"                |##?        ",
"       ?.      1\u0026##?        ",
"     iQ#:    `)8##\u0026!        ",
"     p##txxxxb###o\\         ",
"     p#########MC.          ",
"     +J#####wdt_            ",
"       }B#Z}^               ",
"                            ",
"                            ",
"                            ",
"\"",
"Label: tensor(3,dtype=Int32,device=cpu-1)"]
        },
           "execution_count": 4,
           "metadata": {},
           "output_type": "execute_result"
          }],
           "source": ["// Inspect data as ASCII and show label\n",
"printfn \"Data: %A\\nLabel: %A\" (data.toImageString()) label\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["### Data Loaders\n",
"\n",
"A data loader handles tasks such as constructing minibatches from an underlying dataset on-the-fly, shuffling the data, and moving the data tensors between devices. In the example below we show a single batch of six MNIST images and their corresponding classification labels.\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 5, "outputs": [
          {
           "data": {
            "text/plain": [""]
        },
           "execution_count": 5,
           "metadata": {},
           "output_type": "execute_result"
          }],
           "source": ["let loader = DataLoader(dataset, shuffle=true, batchSize=6)\n",
"let batch, labels = loader.batch()\n",
"\n",
"printfn \"%A\\nLabels: %A\" (batch.toImageString()) labels\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["In practice a data loader is typically used to iterate over all minibatches in a given dataset in order to feed each minibatch through a machine learning model. One full iteration over the dataset would be called an \"epoch\". Typically you would perform multiple such epochs of iterations during the training of a model.\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 6, "outputs": [],
           "source": ["for epoch = 1 to 10 do\n",
"    for i, data, labels in loader.epoch() do\n",
"        printfn \"Epoch %A, minibatch %A\" epoch (i+1)\n",
"        // Process the minibatch\n",
"        // ...\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["## Models\n",
"\n",
"Many machine learning models are differentiable functions whose parameters can be tuned via [gradient-based optimization](https://en.wikipedia.org/wiki/Gradient_descent), finding an optimum for an objective function that quantifies the fit of the model to a given set of data. These models are typically built as compositions non-linear functions and ready-to-use building blocks such as linear, recurrent, and convolutional layers.\n",
"\n",
"Furnace provides the most commonly used model building blocks including convolutions, transposed convolutions, batch normalization, dropout, recurrent and other architectures.\n",
"\n",
"See the [Furnace.Model](/Furnace/reference/furnace-model.html) namespace for the full API reference.\n",
"\n",
"### Constructing models, PyTorch style\n",
"\n",
"If you have experience with [PyTorch](https://pytorch.org/), you would find the following way of model definition familiar. Let\u0027s look at an example of a [generative adversarial network (GAN)](https://arxiv.org/abs/1406.2661) architecture.\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 7, "outputs": [
          {
           "data": {
            "text/plain": [""]
        },
           "execution_count": 7,
           "metadata": {},
           "output_type": "execute_result"
          }],
           "source": ["open Furnace.Model\n",
"open Furnace.Compose\n",
"\n",
"// PyTorch style\n",
"\n",
"// Define a model class inheriting the base\n",
"type Generator(nz: int) =\n",
"    inherit Model()\n",
"    let fc1 = Linear(nz, 256)\n",
"    let fc2 = Linear(256, 512)\n",
"    let fc3 = Linear(512, 1024)\n",
"    let fc4 = Linear(1024, 28*28)\n",
"    do base.addModel(fc1, fc2, fc3, fc4)\n",
"    override self.forward(x) =\n",
"        x\n",
"        |\u003e FurnaceImage.view([-1;nz])\n",
"        |\u003e fc1.forward\n",
"        |\u003e FurnaceImage.leakyRelu(0.2)\n",
"        |\u003e fc2.forward\n",
"        |\u003e FurnaceImage.leakyRelu(0.2)\n",
"        |\u003e fc3.forward\n",
"        |\u003e FurnaceImage.leakyRelu(0.2)\n",
"        |\u003e fc4.forward\n",
"        |\u003e FurnaceImage.tanh\n",
"\n",
"// Define a model class inheriting the base\n",
"type Discriminator(nz:int) =\n",
"    inherit Model()\n",
"    let fc1 = Linear(28*28, 1024)\n",
"    let fc2 = Linear(1024, 512)\n",
"    let fc3 = Linear(512, 256)\n",
"    let fc4 = Linear(256, 1)\n",
"    do base.addModel(fc1, fc2, fc3, fc4)\n",
"    override self.forward(x) =\n",
"        x\n",
"        |\u003e FurnaceImage.view([-1;28*28])\n",
"        |\u003e fc1.forward\n",
"        |\u003e FurnaceImage.leakyRelu(0.2)\n",
"        |\u003e FurnaceImage.dropout(0.3)\n",
"        |\u003e fc2.forward\n",
"        |\u003e FurnaceImage.leakyRelu(0.2)\n",
"        |\u003e FurnaceImage.dropout(0.3)\n",
"        |\u003e fc3.forward\n",
"        |\u003e FurnaceImage.leakyRelu(0.2)\n",
"        |\u003e FurnaceImage.dropout(0.3)\n",
"        |\u003e fc4.forward\n",
"        |\u003e FurnaceImage.sigmoid\n",
"\n",
"// Instantiate the defined classes\n",
"let nz = 128\n",
"let gen = Generator(nz)\n",
"let dis = Discriminator(nz)\n",
"\n",
"print gen\n",
"print dis\n"]
          }
,
          {
           "cell_type": "markdown",
           "metadata": {},
           
           "source": ["### Constructing models, Furnace style\n",
"\n",
"A key advantage of Furnace lies in the [functional programming](https://en.wikipedia.org/wiki/Functional_programming) paradigm enabled by the F# language, where functions are first-class citizens, many algorithms can be constructed by applying and composing functions, and differentiation operations can be expressed as composable [higher-order functions](https://en.wikipedia.org/wiki/Higher-order_function). This allows very succinct (and beautiful) machine learning code to be expressed as a powerful combination of [lambda calculus](https://en.wikipedia.org/wiki/Lambda_calculus) and [differential calculus](https://en.wikipedia.org/wiki/Differential_calculus).\n",
"\n",
"For example, the following constructs the same GAN architecture (that we constructed in PyTorch style in the previous section) using Furnace\u0027s `--\u003e` composition operator, which allows you to seamlessly compose `Model` instances and differentiable `Tensor-\u003eTensor` functions.\n",
"\n"]
          }
,
          {
           "cell_type": "code",
           "metadata": {},
            "execution_count": 8, "outputs": [
          {
           "data": {
            "text/plain": [""]
        },
           "execution_count": 8,
           "metadata": {},
           "output_type": "execute_result"
          }],
           "source": ["// Furnace style\n",
"\n",
"// Model as a composition of models and Tensor-\u003eTensor functions\n",
"let generator =\n",
"    FurnaceImage.view([-1;nz])\n",
"    --\u003e Linear(nz, 256)\n",
"    --\u003e FurnaceImage.leakyRelu(0.2)\n",
"    --\u003e Linear(256, 512)\n",
"    --\u003e FurnaceImage.leakyRelu(0.2)\n",
"    --\u003e Linear(512, 1024)\n",
"    --\u003e FurnaceImage.leakyRelu(0.2)\n",
"    --\u003e Linear(1024, 28*28)\n",
"    --\u003e FurnaceImage.tanh\n",
"\n",
"// Model as a composition of models and Tensor-\u003eTensor functions\n",
"let discriminator =\n",
"    FurnaceImage.view([-1; 28*28])\n",
"    --\u003e Linear(28*28, 1024)\n",
"    --\u003e FurnaceImage.leakyRelu(0.2)\n",
"    --\u003e FurnaceImage.dropout(0.3)\n",
"    --\u003e Linear(1024, 512)\n",
"    --\u003e FurnaceImage.leakyRelu(0.2)\n",
"    --\u003e FurnaceImage.dropout(0.3)\n",
"    --\u003e Linear(512, 256)\n",
"    --\u003e FurnaceImage.leakyRelu(0.2)\n",
"    --\u003e FurnaceImage.dropout(0.3)\n",
"    --\u003e Linear(256, 1)\n",
"    --\u003e FurnaceImage.sigmoid\n",
"\n",
"print generator\n",
"print discriminator\n"]
          }],
            "metadata": {
            "kernelspec": {"display_name": ".NET (F#)", "language": "F#", "name": ".net-fsharp"},
            "langauge_info": {
        "file_extension": ".fs",
        "mimetype": "text/x-fsharp",
        "name": "C#",
        "pygments_lexer": "fsharp",
        "version": "4.5"
        }
        },
            "nbformat": 4,
            "nbformat_minor": 1
        }
        

